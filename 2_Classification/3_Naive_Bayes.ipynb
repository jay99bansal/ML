{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes' Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'no']\n"
     ]
    }
   ],
   "source": [
    "class CategoricalNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_log_prior_ = None\n",
    "        self.feature_log_prob_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit the Naive Bayes classifier to the training data.\n",
    "        Args:\n",
    "            X (list of list): The features of the training data.\n",
    "            y (list): The target labels.\n",
    "        \"\"\"\n",
    "        # Convert data to internal representation\n",
    "        from collections import defaultdict\n",
    "        import numpy as np\n",
    "\n",
    "        # Calculate class priors\n",
    "        unique_classes = set(y)\n",
    "        class_count = {cls: y.count(cls) for cls in unique_classes}\n",
    "        total_samples = len(y)\n",
    "        self.classes_ = list(unique_classes)\n",
    "        self.class_log_prior_ = {cls: np.log(class_count[cls] / total_samples) for cls in unique_classes}\n",
    "\n",
    "        # Calculate feature probabilities per class\n",
    "        feature_counts = {cls: [defaultdict(int) for _ in range(len(X[0]))] for cls in unique_classes}\n",
    "        for xi, yi in zip(X, y):\n",
    "            for idx, feature in enumerate(xi):\n",
    "                feature_counts[yi][idx][feature] += 1\n",
    "\n",
    "        self.feature_log_prob_ = {\n",
    "            cls: [{feat: np.log((feature_counts[cls][idx].get(feat, 0) + 1) / (class_count[cls] + len(feature_counts[cls][idx])))\n",
    "                   for feat in feature_counts[cls][idx]} for idx in range(len(X[0]))]\n",
    "            for cls in unique_classes\n",
    "        }\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict class labels for the input features.\n",
    "        Args:\n",
    "            X (list of list): The features to predict.\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        predictions = []\n",
    "        for xi in X:\n",
    "            class_probs = {}\n",
    "            for cls in self.classes_:\n",
    "                total_log_prob = self.class_log_prior_[cls]\n",
    "                for idx, feature in enumerate(xi):\n",
    "                    total_log_prob += self.feature_log_prob_[cls][idx].get(feature, -np.inf)  # handle unseen features\n",
    "                class_probs[cls] = total_log_prob\n",
    "            predictions.append(max(class_probs, key=class_probs.get))\n",
    "        return predictions\n",
    "\n",
    "# Example usage\n",
    "data = [['sunny', 'hot', 'high', False],\n",
    "        ['sunny', 'hot', 'high', True],\n",
    "        ['overcast', 'hot', 'high', False],\n",
    "        ['rainy', 'mild', 'high', False],\n",
    "        ['rainy', 'cool', 'normal', False]]\n",
    "\n",
    "labels = ['no', 'no', 'yes', 'yes', 'no']\n",
    "\n",
    "# Create and train the classifier\n",
    "model = CategoricalNaiveBayes()\n",
    "model.fit(data, labels)\n",
    "\n",
    "# Make predictions\n",
    "test_data = [['rainy', 'cool', 'normal', True],\n",
    "             ['sunny', 'mild', 'high', False]]\n",
    "\n",
    "print(model.predict(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['blue' 'red' 'blue' 'red' 'red']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.means = {}\n",
    "        self.variances = {}\n",
    "        self.priors = {}\n",
    "        self.classes = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit the Naive Bayes classifier to the training data.\n",
    "        Args:\n",
    "            X (numpy.ndarray): The features of the training data.\n",
    "            y (numpy.ndarray): The target labels.\n",
    "        \"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        for cls in self.classes:\n",
    "            X_cls = X[y == cls]\n",
    "            self.means[cls] = np.mean(X_cls, axis=0)\n",
    "            self.variances[cls] = np.var(X_cls, axis=0)\n",
    "            self.priors[cls] = X_cls.shape[0] / X.shape[0]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Compute probabilities of possible outcomes for samples in X.\n",
    "        Args:\n",
    "            X (numpy.ndarray): The input features.\n",
    "        \"\"\"\n",
    "        eps = 1e-6  # to avoid division by zero in variance\n",
    "        likelihoods = []\n",
    "        for cls in self.classes:\n",
    "            prior = np.log(self.priors[cls])\n",
    "            class_mean = self.means[cls]\n",
    "            class_var = self.variances[cls]\n",
    "            exponent = -0.5 * np.sum(((X - class_mean) ** 2) / (class_var + eps), axis=1)\n",
    "            log_prob = exponent - 0.5 * np.sum(np.log(2. * np.pi * (class_var + eps)))\n",
    "            total_log_prob = prior + log_prob\n",
    "            likelihoods.append(total_log_prob)\n",
    "        return np.column_stack(likelihoods)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Perform classification on an array of test vectors X.\n",
    "        Args:\n",
    "            X (numpy.ndarray): The input features.\n",
    "        \"\"\"\n",
    "        log_probs = self.predict_proba(X)\n",
    "        return self.classes[np.argmax(log_probs, axis=1)]\n",
    "\n",
    "# Example usage\n",
    "# Create some example data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 3)  # 100 samples, 3 features\n",
    "y = np.random.choice(['red', 'blue'], 100)  # Binary target\n",
    "\n",
    "# Create and train the classifier\n",
    "model = GaussianNaiveBayes()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "test_data = np.random.rand(5, 3)  # Some new random test data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
