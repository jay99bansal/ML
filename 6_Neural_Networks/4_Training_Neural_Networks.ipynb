{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.3137\n",
      "Updated Weights and Biases:\n",
      "W[1]:\n",
      " [[ 0.93154205  1.37203345]\n",
      " [ 0.74225569 -0.4905506 ]]\n",
      "b[1]:\n",
      " [[-0.00659469]\n",
      " [-0.12003103]]\n",
      "W[2]:\n",
      " [[-0.26436085 -1.10019516]]\n",
      "b[2]:\n",
      " [[-0.53181587]]\n",
      "Epoch 2, Loss: 1.7029\n",
      "Updated Weights and Biases:\n",
      "W[1]:\n",
      " [[ 0.90992164  1.32879265]\n",
      " [ 0.74225569 -0.4905506 ]]\n",
      "b[1]:\n",
      " [[-0.02821509]\n",
      " [-0.12003103]]\n",
      "W[2]:\n",
      " [[ 0.03570463 -1.10019516]]\n",
      "b[2]:\n",
      " [[-0.45003219]]\n",
      "Epoch 3, Loss: 0.8680\n",
      "Updated Weights and Biases:\n",
      "W[1]:\n",
      " [[ 0.91199329  1.33293593]\n",
      " [ 0.74225569 -0.4905506 ]]\n",
      "b[1]:\n",
      " [[-0.02614345]\n",
      " [-0.12003103]]\n",
      "W[2]:\n",
      " [[ 0.24106026 -1.10019516]]\n",
      "b[2]:\n",
      " [[-0.39201052]]\n",
      "Epoch 4, Loss: 0.4878\n",
      "Updated Weights and Biases:\n",
      "W[1]:\n",
      " [[ 0.92129815  1.35154566]\n",
      " [ 0.74225569 -0.4905506 ]]\n",
      "b[1]:\n",
      " [[-0.01683858]\n",
      " [-0.12003103]]\n",
      "W[2]:\n",
      " [[ 0.3781558  -1.10019516]]\n",
      "b[2]:\n",
      " [[-0.35341078]]\n",
      "Epoch 5, Loss: 0.3104\n",
      "Updated Weights and Biases:\n",
      "W[1]:\n",
      " [[ 0.93138819  1.37172574]\n",
      " [ 0.74225569 -0.4905506 ]]\n",
      "b[1]:\n",
      " [[-0.00674855]\n",
      " [-0.12003103]]\n",
      "W[2]:\n",
      " [[ 0.47441328 -1.10019516]]\n",
      "b[2]:\n",
      " [[-0.32672856]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation Functions and Their Derivatives\n",
    "def relu(z):\n",
    "    \"\"\"ReLU activation function\"\"\"\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    \"\"\"Derivative of ReLU\"\"\"\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    \"\"\"Derivative of Sigmoid\"\"\"\n",
    "    return a * (1 - a)\n",
    "\n",
    "# Binary Cross-Entropy Loss\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"Binary Cross-Entropy Loss\"\"\"\n",
    "    return -np.mean(y_true * np.log(y_pred + 1e-15) + (1 - y_true) * np.log(1 - y_pred + 1e-15))\n",
    "\n",
    "# Neural Network Implementation\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with given layer sizes and learning rate.\n",
    "        :param layer_sizes: List of integers specifying the number of neurons in each layer.\n",
    "        :param learning_rate: Learning rate for gradient descent.\n",
    "        \"\"\"\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i + 1], layer_sizes[i]))\n",
    "            self.biases.append(np.random.randn(layer_sizes[i + 1], 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform forward propagation.\n",
    "        :param x: Input data.\n",
    "        :return: Activations and weighted sums for all layers.\n",
    "        \"\"\"\n",
    "        activations = [x]\n",
    "        z_values = []\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(self.weights[i], activations[-1]) + self.biases[i]\n",
    "            z_values.append(z)\n",
    "\n",
    "            # Apply activation functions\n",
    "            if i == len(self.weights) - 1:  # Output layer\n",
    "                a = sigmoid(z)\n",
    "            else:  # Hidden layers\n",
    "                a = relu(z)\n",
    "\n",
    "            activations.append(a)\n",
    "\n",
    "        return activations, z_values\n",
    "\n",
    "    def backward(self, x, y, activations, z_values):\n",
    "        \"\"\"\n",
    "        Perform backpropagation.\n",
    "        :param x: Input data.\n",
    "        :param y: Ground truth output.\n",
    "        :param activations: List of activations from forward pass.\n",
    "        :param z_values: List of weighted sums from forward pass.\n",
    "        :return: Gradients for weights and biases.\n",
    "        \"\"\"\n",
    "        m = x.shape[1]  # Number of training examples\n",
    "        dw = [None] * len(self.weights)\n",
    "        db = [None] * len(self.biases)\n",
    "        dz = [None] * len(self.weights)\n",
    "\n",
    "        # Output layer error\n",
    "        dz[-1] = activations[-1] - y\n",
    "        dw[-1] = (1 / m) * np.dot(dz[-1], activations[-2].T)\n",
    "        db[-1] = (1 / m) * np.sum(dz[-1], axis=1, keepdims=True)\n",
    "\n",
    "        # Backpropagate through hidden layers\n",
    "        for i in range(len(self.weights) - 2, -1, -1):\n",
    "            dz[i] = np.dot(self.weights[i + 1].T, dz[i + 1]) * relu_derivative(z_values[i])\n",
    "            dw[i] = (1 / m) * np.dot(dz[i], activations[i].T)\n",
    "            db[i] = (1 / m) * np.sum(dz[i], axis=1, keepdims=True)\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "    def update_parameters(self, dw, db):\n",
    "        \"\"\"\n",
    "        Update weights and biases using gradients.\n",
    "        \"\"\"\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * dw[i]\n",
    "            self.biases[i] -= self.learning_rate * db[i]\n",
    "\n",
    "    def train(self, x, y, epochs):\n",
    "        \"\"\"\n",
    "        Train the neural network using gradient descent.\n",
    "        :param x: Input data.\n",
    "        :param y: Ground truth output.\n",
    "        :param epochs: Number of training epochs.\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Forward propagation\n",
    "            activations, z_values = self.forward(x)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = binary_cross_entropy(y, activations[-1])\n",
    "\n",
    "            # Backward propagation\n",
    "            dw, db = self.backward(x, y, activations, z_values)\n",
    "\n",
    "            # Update parameters\n",
    "            self.update_parameters(dw, db)\n",
    "\n",
    "            # Print loss and weights\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}\")\n",
    "            print(\"Updated Weights and Biases:\")\n",
    "            for i in range(len(self.weights)):\n",
    "                print(f\"W[{i + 1}]:\\n\", self.weights[i])\n",
    "                print(f\"b[{i + 1}]:\\n\", self.biases[i])\n",
    "\n",
    "# Define the network structure based on the example\n",
    "layer_sizes = [2, 2, 1]  # Input layer (2 neurons), 1 hidden layer (2 neurons), output layer (1 neuron)\n",
    "\n",
    "# Initialize the neural network\n",
    "nn = NeuralNetwork(layer_sizes, learning_rate=0.1)\n",
    "\n",
    "# Input and output data\n",
    "x = np.array([[1], [2]])  # Input vector x = [1, 2]\n",
    "y = np.array([[1]])       # Actual output y = 1\n",
    "\n",
    "# Train the neural network for 5 epochs\n",
    "nn.train(x, y, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
